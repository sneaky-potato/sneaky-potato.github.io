<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=content-type content="text/html"><meta name=viewport content="width=device-width,initial-scale=1"><title itemprop=name>A Computer Vision Problem | Potato</title><meta property="og:title" content="A Computer Vision Problem | Potato"><meta name=twitter:title content="A Computer Vision Problem | Potato"><meta itemprop=name content="A Computer Vision Problem | Potato"><meta name=application-name content="A Computer Vision Problem | Potato"><meta property="og:site_name" content="Awesome hugo blog"><meta name=description content="CV Task given as an assignemnt in ARK"><meta itemprop=description content="CV Task given as an assignemnt in ARK"><meta property="og:description" content="CV Task given as an assignemnt in ARK"><meta name=twitter:description content="CV Task given as an assignemnt in ARK"><meta property="og:locale" content="en-us"><meta name=language content="en-us"><link rel=alternate hreflang=en href=https://sneaky-potato.github.io/blog/cv/ title><meta name=generator content="Hugo 0.152.1"><meta property="og:url" content="https://sneaky-potato.github.io/blog/cv/"><meta property="og:site_name" content="Potato"><meta property="og:title" content="A Computer Vision Problem"><meta property="og:description" content="CV Task given as an assignemnt in ARK"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2022-03-05T00:00:00+00:00"><meta property="article:modified_time" content="2022-03-05T00:00:00+00:00"><meta property="article:tag" content="Tech"><meta name=twitter:card content="summary"><meta name=twitter:title content="A Computer Vision Problem"><meta name=twitter:description content="CV Task given as an assignemnt in ARK"><link rel=canonical href=https://sneaky-potato.github.io/blog/cv/><link href=/style.min.2d921c18cf1ec555ffc03d59a8adc211c402c68c930c27d6a0c306ab175a8d09.css rel=stylesheet><link href=/code-highlight.min.706d31975fec544a864cb7f0d847a73ea55ca1df91bf495fd12a177138d807cf.css rel=stylesheet><link rel=apple-touch-icon sizes=180x180 href=/icons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/icons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/icons/favicon-16x16.png><link rel=mask-icon href=/icons/safari-pinned-tab.svg><link rel="shortcut icon" href=/favicon.ico><link rel=manifest href=https://sneaky-potato.github.io/site.webmanifest><meta name=msapplication-config content="/browserconfig.xml"><meta name=msapplication-TileColor content="#2d89ef"><meta name=theme-color content="#434648"><link rel=icon type=image/svg+xml href=/icons/favicon.svg></head><body data-theme=dark class=notransition><script src=/js/theme.min.8961c317c5b88b953fe27525839672c9343f1058ab044696ca225656c8ba2ab0.js integrity="sha256-iWHDF8W4i5U/4nUlg5ZyyTQ/EFirBEaWyiJWVsi6KrA="></script><div class=navbar role=navigation><nav class=menu aria-label="Main Navigation"><a href=https://sneaky-potato.github.io/ class=logo><svg width="25" height="25" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-home"><title/><path d="M3 9l9-7 9 7v11a2 2 0 01-2 2H5a2 2 0 01-2-2z"/><polyline points="9 22 9 12 15 12 15 22"/></svg>
</a><input type=checkbox id=menu-trigger class=menu-trigger>
<label for=menu-trigger><span class=menu-icon><svg width="25" height="25" stroke="currentColor" fill="none" viewBox="0 0 14 14"><title>Menu</title><path stroke-linecap="round" stroke-linejoin="round" d="M10.595 7H3.40726"/><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 3.51488H3.49301"/><path stroke-linecap="round" stroke-linejoin="round" d="M10.5096 10.4851H3.49301"/><path stroke-linecap="round" stroke-linejoin="round" d="M.5 12.5V1.5c0-.552285.447715-1 1-1h11C13.0523.5 13.5.947715 13.5 1.5v11C13.5 13.0523 13.0523 13.5 12.5 13.5H1.5C.947715 13.5.5 13.0523.5 12.5z"/></svg></span></label><div class=trigger><ul class=trigger-container><li><a class=menu-link href=/>Home</a></li><li><a class="menu-link active" href=/blog/>Blog</a></li><li><a class=menu-link href=/about/>About</a></li><li class=menu-separator><span>|</span></li></ul><a id=mode href=#><svg class="mode-sunny" width="21" height="21" viewBox="0 0 14 14" stroke-width="1"><title>LIGHT</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="7" y1=".5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1=".5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"/></g></svg>
<svg class="mode-moon" width="21" height="21" viewBox="0 0 14 14" stroke-width="1"><title>DARK</title><g><circle cx="7" cy="7" r="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="7" y1=".5" x2="7" y2="2.5" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="2.4" y1="2.4" x2="3.82" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1=".5" y1="7" x2="2.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="2.4" y1="11.6" x2="3.82" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="7" y1="13.5" x2="7" y2="11.5" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="11.6" y1="11.6" x2="10.18" y2="10.18" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="13.5" y1="7" x2="11.5" y2="7" fill="none" stroke-linecap="round" stroke-linejoin="round"/><line x1="11.6" y1="2.4" x2="10.18" y2="3.82" fill="none" stroke-linecap="round" stroke-linejoin="round"/></g></svg></a></div></nav></div><div class="wrapper post"><main class=page-content aria-label=Content><article><header class=header><h1 class=header-title>A Computer Vision Problem</h1><div class=post-meta><time datetime=2022-03-05T00:00:00+00:00 itemprop=datePublished>Mar 5, 2022</time></div></header><div class=page-content><div class="lead !mb-9 text-xl">An interesting Computer Vision problem with all my approaches and an elegant solution.</div><p>Original problem statement file and required files <a href="https://drive.google.com/drive/folders/1BDYyxglyihcEPfUyxoK2Iq1567Ymt3PN?usp=sharing">here</a>. This problem was given to me in my sophomore year as a task under my tenure in the ARK perception team.</p><p>I haven&rsquo;t done robotics in a long while (am writing this thing after leaving all that stuff behind), this being the only testimony of me having done those courses on image processing lol.</p><h2 id=problem-statement>Problem Statement</h2><blockquote><p>If none of the following make sense to you and those text files seem like random jargon, this post is <strong>NOT</strong> for you. Go and move on, you&rsquo;re better off not knowing about all this altogether (unless you want to pursue a career in robotics, maybe)</p></blockquote><p>A breif version of the problem goes like this-</p><ul><li>given 30 files, 10 each of types 0 (RGB, jpg), 1 (Segmentation, jpg) and 2 (Pose, txt)</li><li>images are 256x144 in size</li><li>a projective pinhole camera is used everywhere</li><li>camera has a horizontal field-of-view (FOV) of 90°</li><li>assumptions-<ul><li>the distortion parameters are zero</li><li>principal point of the image is at its center</li><li>focal length in x direction = focal length in y direction</li></ul></li><li>pose data is the position of the camera in the world coordinates in the NED coordinate system</li><li>it is stored in the form of an orientation quaternion and a position vector</li></ul><h3 id=objective>Objective</h3><p>Using the information provided, calculate</p><ol><li>length of the side of the cube</li><li>x,y,z coordinates of the centroid of the cube</li></ol><div class="flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900"><span class="pe-3 text-primary-400"></span><span class=dark:text-neutral-300><strong>WARNING</strong>: Proceed ahead only after you&rsquo;re ready for the solution (after giving the problem some thought) and are already familiar with the basics of image processing and Computer Vision</span></div><h2 id=initial-attempt>Initial Attempt</h2><p>I started to recall everything that I&rsquo;d gone through while doing my courses. Thought about applying all sorts of stuff like homography, constructing the camera matrices, using stereo pairs (seemed illogical at that time).</p><p>My line of thought only seemed to go in one direction- use all images separately.</p><p>But then I hit a dead wall when I couldn&rsquo;t convert the 2D coordiantes to 3D ones (was the essence of the entire problem). I thought maybe the information given was insufficient and I needed a <code>scale</code> factor.</p><p>The whole 3D -> 2D conversion eats up the depth information completely, hence a (x y z) -> (x&rsquo; y&rsquo;) mapping exists. However to do the opposite, you need to materialize the depth information from somewhere.</p><p>But then again, I wasn&rsquo;t using all the information provided to me, hinting towards my shortcoming.</p><h2 id=my-solution-approach>My solution approach</h2><h3 id=get-em-curves-ehm-corners>Get em curves, ehm corners</h3><p>I started to think of some use case to the segmentation masks provided. I had to locate corners in tha image according to image coordiantes. So there it was, I used the segmentation masks, ran them through the Harris corner detector function of OpenCV.</p><p>The results were good honestly,</p><p><img src=/corners.png alt=corner></p><p>but</p><p><img src=/failedcorners.png alt=failedcorner></p><p>Hmm, but hey I had many coresponding points atleast.</p><h3 id=2d---3d>2D -> 3D</h3><p>There are a few ways in which you can achieve this. The simplest being tracing out lights rays from the corners to the center of the camera (possible with the given pose data) and then finding the intersection.</p><p>But then this method is bound to introduce noise. You&rsquo;ll never be sure about the intersection at all. In fact you might even will have to find the point of minimum distance instead. Because, in robotics, error and noise are gonna be your arch nemesis always. Consequenty, a large part of your time will often be invested with dealing with the error.</p><p>I had to use <a href=https://en.wikipedia.org/wiki/Triangulation_(computer_vision)>Triangulation</a>. All what remained was to simulate the thing<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> on the actual problem.</p><h3 id=evil-matrices>Evil matrices</h3><p>The key step behind all of this to work appreciably was- not screwing up simple calculation. Simple, right?</p><p>Funnily enough, I managed to screw up the calculation each time I made the extrinsic and intrisic matrices. Why? Because the <code>best</code> values I could come up with were-</p><ul><li>55.75492842884244</li><li>66.53124150897686</li><li>73.18385840990788</li><li>9.655399061410336</li></ul><p>These are supposed to be side lenghts of the cube :clown:. Another run of the simulation yielded side lenghts of the order of 10^-3 to 10^3 (in the same set :clown: :clown:).</p><p>My best guess to where I was going wrong back then would be direction of axes and the position of the 2D origin (I don&rsquo;t remember, even if I did, I wouldn&rsquo;t reveal it like that ofc) But then I also remember checking my camera parameters like for the N^th time.</p><p>I even tried plotting the 3D coordinates after tweaking the paramteres like a bazillion times, only to get this</p><p><img src=/plot.png alt=plot></p><p>This, well this is supposed to be a face of the cube, which should be, idk, slightly squarish I guess? (Even the ground corner coordinates didn&rsquo;t seem to go along the NED direction thing)</p><p>Double checked it with my peers at ARK, asked the seniors about the validity of pose data only to hit a dead end.</p><h2 id=result>Result</h2><p>There were no results, I couldn&rsquo;t solve it.</p><p>However after this thing was over and we were discussing about it, turns out one of us at ARK did indeed manage to get a very tight approximate.</p><p>I&rsquo;ll just quote the solution algorithm he followed here.</p><h3 id=ml-and-approximation>ML and approximation</h3><p>ML algorithms in their core are essentially complex approximation methods. Interestingly we can apply a well known method to get to the solution here.</p><p>Gradient descent, get a parametric equation for the original complicated equation and bam a very clean solution.</p><p>Coming directly from his repo&rsquo;s README.md</p><blockquote><p>The final approach was to create a parametric model for a cube in 3D space lying on a horizontal surface. Such a cube is sufficiently described by 5 parameters - the x, y, z coordinates of its centroid, the angle of rotation about the vertical (z-axis), and the side length. The parameterization used has s as the semi side length for a cleaner formula representation. The corners of this cube can be found in terms of these parameters and keys/color descriptors can be assigned in cyclic order. These keys were manually assigned, although it is possible to automatically assign them using the detected color data. With this description, the distance of each corner can be found to all the corresponding projection lines and the sum of the squares of these distances is taken as a loss function. Tensorflow is then used to automatically differentiate and optimize the values of these parameters using the Adam optimizer.</p></blockquote><p>Here&rsquo;s the <a href=https://github.com/IshanManchanda/ark-ros-cv-task>link</a> to his repo</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=http://www.cs.cmu.edu/~16385/s17/Slides/11.4_Triangulation.pdf>Triangulation, 16-385 Computer Vision, Spring 2020</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></article><script src=https://utteranc.es/client.js repo=sneaky-potato/sneaky-potato.github.io issue-term=pathname label=comment theme=github-dark-orange crossorigin=anonymous async></script></main></div><footer class=footer><span class=footer_item></span>&nbsp;<div class=footer_social-icons></div><small class=footer_copyright>© 2025 Ashwani Kumar Kamal.</small></footer><a href=# title id=totop><svg width="48" height="48" fill="currentColor" stroke="currentColor" viewBox="0 96 960 960"><path d="M283 704.739 234.261 656 480 410.261 725.739 656 677 704.739l-197-197-197 197z"/></svg>
</a><script src=https://sneaky-potato.github.io/js/main.min.35f435a5d8eac613c52daa28d8af544a4512337d3e95236e4a4978417b8dcb2f.js integrity="sha256-NfQ1pdjqxhPFLaoo2K9USkUSM30+lSNuSkl4QXuNyy8="></script></body></html>